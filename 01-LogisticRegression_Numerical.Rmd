# Binary logistic regression with one numerical explanatory variable {-}

Here we shall begin by fitting a logistic regression model with one numerical explanatory variable. Let's return to the `evals` data from the `moderndive` package that we examined in Week 3.

## Teaching evaluation scores {-}

Recall from previous weeks that student feedback in higher education is extremely important when it comes to the evaluation of teaching techniques, materials, and improvements in teaching methods and technologies. However, there have been studies into potential bias factors when feedback is provided, such as the physical appearance of the teacher; see [Economics of Education Review](https://www.journals.elsevier.com/economics-of-education-review/) for details. Here, we shall return to the study of student evaluations of $n=463$ professors from The University of Texas at Austin. 

Previously, we looked at **teaching score** as our continuous response variable and **beauty score** as our explanatory variable. Now we shall consider **gender** as our response variable, and hence shall have a binary response variable (female/male). We will examine if there is any difference in **gender** by **age** of the teaching instructors within the `evals` data set. 

First, let's start by selecting the variables of interest from the `evals` data set:

```{r evals1, echo = c(1), eval = TRUE}
evals.gender <- evals %>%
                  select(gender, age)
evals.gender
```

Now, let's look at a boxplot of `age` by `gender` to get an initial impression of the data:

```{r, fig.cap = "Teaching instructor age by gender.", fig.align = "center"}
ggplot(data = evals.gender, aes(x = gender, y = age, fill = gender)) +
  geom_boxplot() +
  labs(x = "Gender", y = "Age")+ 
  theme(legend.position = "none")
```

Here we can see that the male teaching instructors tend to be older than that of their female colleagues. Now, let's fit a logistic regression model to see whether age is a significant predictor of the odds of a teaching instructor being male or female.

## Log-odds {-}

To fit a logistic regression model we will use the generalised linear model function `glm`, which acts in a very similar manner to the `lm` function we have used previously. We only have to deal with an additional argument. The logistic regression model with **gender** as the response and **age** as the explanatory variable is given by:

```{r model1, echo = TRUE, eval = TRUE}
model <- glm(gender ~ age, data = evals.gender, 
             family = binomial(link = "logit"))
```

Here we include the additional `family` argument, which states the distribution and link function we would like to use. Hence `family = binomial(link = "logit")` states we have a binary response variable, and thus have a binomial distribution, with its corresponding **logit link** function. Now, let's take a look at the summary produced from our logistic regression model:


```{r mod1sum, echo = TRUE, eval = TRUE}
model %>%
  summary()
```

An alternative to `summary()` is the `summ()` function in the `jtools` [package](https://cran.r-project.org/web/packages/jtools/vignettes/summ.html) which allows a lot more control over what is included in the summary table and more nicely formatted output.  Here is the default output for the model fitted above... 

```{r mod2, echo = TRUE, eval = TRUE, warning = FALSE}
summ(model)
```

To interpret this fitted model, firstly we note that the baseline category for our binary response is `female`. This is due to the default baseline in R being taken as the one which comes first alphabetically, which can be seen from the `levels` function:

```{r levels, echo = TRUE, eval = TRUE}
levels(evals.gender$gender)
```

```{r mod1coefs1, echo = FALSE, eval = TRUE}
mod1coefs <- round(coef(model), 2)
```

This means that estimates from the logistic regression model are for a change on the **log-odds** scale for `males` in comparison to the response baseline `females`.  We can extract the estimated coefficients using `mod1coefs <- round(coef(model), 2)` and then use the inline code `` `r
mod1coefs[1]` `` and `` `r
mod1coefs[2]` `` to report the fitted model as follows...

```{r mod1coefs2, echo = TRUE, eval = TRUE}
mod1coefs <- round(coef(model), 2)
```

`\begin{align}`

`\ln\left(\frac{p}{1-p}\right) &= \alpha + \beta \cdot \textrm{age} = ` ``  `r
mod1coefs[1]`   +   `r
mod1coefs[2]` `` `\cdot \textrm{age} \nonumber`

`\end{align}`


\begin{align}
\ln\left(\frac{p}{1-p}\right) &= \alpha + \beta \cdot \textrm{age} = `r mod1coefs[1]` + `r mod1coefs[2]` \cdot \textrm{age} \nonumber
\end{align}


where $p = \textrm{Prob}\left(\textrm{Male}\right)$ and $1 - p = \textrm{Prob}\left(\textrm{Female}\right)$. Hence, the **log-odds** of the instructor being male increase by `r mod1coefs[2]` for every one unit increase in `age`. This provides us with a point estimate of how the log-odds changes with age, however, we are also interested in producing a 95% confidence interval for these log-odds. This can be done using the `confint` function in the `MASS` package:

```{r}
confint(model) %>%
  kable()
```

To understand how these endpoints are calculated, consider the following code:
```{r, echo = c(1, 2, 3, 5, 7), eval = TRUE}
mod.coef.logodds <- model %>%
                      summary() %>%
                      coef()
```

```{r, echo = c(1, 3), eval = TRUE}
age.logodds.lower <- mod.coef.logodds["age", "Estimate"] - 
                      1.96 * mod.coef.logodds["age", "Std. Error"]
age.logodds.lower
age.logodds.upper <- mod.coef.logodds["age", "Estimate"] + 
                      1.96 * mod.coef.logodds["age", "Std. Error"]
age.logodds.upper
```

Hence the point estimate for the log-odds is `r mod1coefs[2]`, which has a corresponding 95% confidence interval of (`r round(age.logodds.lower, 2)`, `r round(age.logodds.upper, 2)`). This can be displayed graphically using the `plot_model` function from the `sjPlot` package by simply passing our `model` as an argument:

```{r, fig.cap = "The log-odds of age for male instructors.", fig.align="center"}
plot_model(model, show.values = TRUE, transform = NULL,
           title = "Log-Odds (Male instructor)", show.p = FALSE)
```

Some of the interesting arguments that can be passed to the `plot_model` function are:

  * `show.values = TRUE/FALSE`: Whether the log-odds/odds values should be displayed;
  * `show.p = TRUE/FALSE`: Adds asterisks that indicate the significance level of estimates to the value labels;
  * `transform`: A character vector naming the function that will be applied to the estimates. The default transformation uses `exp` to display the odds ratios, while `transform = NULL` displays the log-odds; and
  * `vline.color`: colour of the vertical "zero effect" line.

Further details on using `plot_model` can be found [here](https://strengejacke.wordpress.com/2017/10/23/one-function-to-rule-them-all-visualization-of-regression-models-in-rstats-w-sjplot/) and [here](https://strengejacke.github.io/sjPlot/index.html). 

Now, let's add the estimates of the log-odds to our data set:

```{r, echo = c(1)}
evals.gender <- evals.gender %>%
                  mutate(logodds.male = predict(model))
head(evals.gender)
```

<br>

```{r MCQ1, echo=FALSE}
opts_Q1 <- sample(c(answer = "1.206",
                    "1.017",
                    "0.828",
                    "-0.746"))
```

**What is the log-odds of a 62 year old instructor being male?**
`r longmcq(opts_Q1)`

<br>

```{r MCQ2, echo=FALSE}
opts_Q2 <- sample(c(answer = "-0.872",
                    "-0.746",
                    "-0.557",
                    "-0.620"))
```

**What is the log-odds of a 29 year old instructor being male?**
`r longmcq(opts_Q2)`

<br>


## Odds {-}

Typically we would like to work on the **odds** scale as it is easier to interpret an odds-ratio as opposed to the log-odds-ratio. To obtain the odds we simply exponentiate the log-odds, that is

\begin{align}
\frac{p}{1-p} &= \exp\left(\alpha + \beta \cdot \textrm{age}\right), \nonumber
\end{align}

```{r, echo = TRUE, eval = TRUE}
model %>%
 coef() %>%
  exp()
```

```{r, echo = FALSE, eval = TRUE}
mod1.odds <- model %>%
              coef() %>%
              exp()
```

On the odds scale, the value of the intercept (`r round(mod1.odds["(Intercept)"], 2)`) gives the odds of a teaching instructor being male given their `age = 0`, which is obviously not a viable age for a teaching instructor, and hence why this value is very close to zero. For `age` we have an odds of `r round(mod1.odds[("age")], 2)`, which indicates that for every 1 unit increase in age, the odds of the teaching instructor being male increase by a factor of `r round(mod1.odds[("age")], 2)`. So how is this calculated? Let's look at the odds-ratio obtained from instructors aged 51 and 52 years old, that is, a one unit difference:

\begin{align}
\small
\frac{\mbox{Odds}_{\scriptsize \mbox{age=52}}}{\mbox{Odds}_{\scriptsize \mbox{age=51}}} = \left(\frac{\frac{p_{\scriptsize \mbox{age=52}}}{1 - p_{\scriptsize \mbox{age=52}}}}{\frac{p_{\scriptsize \mbox{age=51}}}{1 - p_{\scriptsize \mbox{age=51}}}}\right) = \frac{\exp\left(\alpha + \beta \cdot 52\right)}{\exp\left(\alpha + \beta \cdot 51\right)} = \exp\left(\beta \cdot (52 - 51)\right) = \exp\left(`r mod1coefs[2]`\right) = `r round(exp(mod1coefs[2]), 2)`. \nonumber
\end{align}

For example, the odds of a teaching instructor who is 45 years old being male is given by

\begin{align}
\frac{p}{1-p} &= \exp\left(\alpha + \beta \cdot \textrm{age}\right) = \exp\left(`r mod1coefs[1]` + `r mod1coefs[2]` \cdot 45\right) = `r round(exp(mod.coef.logodds["(Intercept)", "Estimate"] + mod.coef.logodds["age", "Estimate"] * 45), 2)`. \nonumber
\end{align}

This can be interpreted as the chances of an instructor who is 45 being male are 15% greater than them being female. We can obtain a 95% confidence interval for the odds by simply exponentiating the lower and upper bounds of our log-odds interval:

```{r, echo = c(1, 3), eval = TRUE}
age.odds.lower <- exp(age.logodds.lower)
age.odds.lower
age.odds.upper <- exp(age.logodds.upper)
age.odds.upper
```

Hence the point estimate for the odds is `r round(mod1.odds["age"], 2)`, which has a corresponding 95% confidence interval of (`r round(age.odds.lower, 2)`, `r round(age.odds.upper, 2)`). This can be displayed graphically using the `plot_model` function from the `sjPlot` package by simply passing our `model` as an argument as well as removing `transform = NULL` (the default transformation is exponential):

```{r, fig.cap = "The odds of age for male instructors.", fig.align="center"}
plot_model(model, show.values = TRUE, axis.lim = c(1,1.5),
           title = "Odds (Male instructor)", show.p = FALSE)
```

**Note**: As the 95% confidence interval is so narrow it is hard to see it displayed in the plot, but it is included by default.  The `axis.lim = c(1,1.5)` argument improves its visibility as seen here.

Now, let's add the estimates of the odds to our data set:

```{r, echo = c(1)}
evals.gender <- evals.gender %>%
                  mutate(odds.male = exp(logodds.male))
head(evals.gender)
```

<br>

```{r MCQ3, echo=FALSE}
opts_Q3 <- sample(c(answer = "1.299",
                    "0.261",
                    "0.537",
                    "0.692"))
```

**What is the odds of a 47 year old instructor being male?**
`r longmcq(opts_Q3)`

<br>

```{r MCQ4, echo=FALSE}
opts_Q4 <- sample(c(answer = "2.289",
                    "2.438",
                    "3.340",
                    "1.779"))
```

**What is the odds of a 56 year old instructor being male?**
`r longmcq(opts_Q4)`

<br>


## Probabilities {-}

We can obtain the probability $p = \textrm{Prob}(\textrm{Male})$ using the following transformation:

\begin{align}
p &= \frac{\exp\left(\alpha + \beta \cdot \textrm{age} \right)}{1 + \exp\left(\alpha + \beta \cdot \textrm{age} \right)}. \nonumber
\end{align}

For example, the probability of a teaching instructor who is 52 years old being male is

\begin{align}
p &= \frac{\exp\left(\alpha + \beta \cdot \textrm{age} \right)}{1 + \exp\left(\alpha + \beta \cdot \textrm{age} \right)}
=\frac{\exp\left(`r mod.coef.logodds["(Intercept)", "Estimate"]` + `r mod.coef.logodds["age", "Estimate"]`\cdot 52 \right)}{1 + \exp\left(`r mod.coef.logodds["(Intercept)", "Estimate"]` + `r mod.coef.logodds["age", "Estimate"]`\cdot 52 \right)} 
= 0.64, \nonumber
\end{align}

which can be computed in R as follows:

```{r}
p.num <- exp(mod.coef.logodds["(Intercept)", "Estimate"] + mod.coef.logodds["age", "Estimate"] * 52)
p.denom <- 1 + p.num
p.num / p.denom
```

The `plogis()` function from the `stats` library can also be used to obtain probabilities from the log-odds:

```{r}
plogis(mod.coef.logodds["(Intercept)", "Estimate"] + mod.coef.logodds["age", "Estimate"] * 52)
```

Let's add the probabilities to our data, which is done using the `fitted()` function:

```{r, echo = c(1)}
evals.gender <- evals.gender %>%
                  mutate(probs.male = fitted(model))
head(evals.gender)
```

**Note**: `predict(model, type = "response")` will also provide the estimated probabilities.

<br>

```{r MCQ5, echo=FALSE}
opts_Q5 <- sample(c(answer = "0.650",
                    "0.350",
                    "0.364",
                    "0.770"))
```

**What is the probability of a 33 year old instructor being female?**
`r longmcq(opts_Q5)`

<br>

```{r MCQ6, echo=FALSE}
opts_Q6 <- sample(c(answer = "0.565",
                    "0.424",
                    "0.709",
                    "0.379"))
```

**What is the probability of a 47 year old instructor being male?**
`r longmcq(opts_Q6)`

<br>

Finally, we can plot the probability of being male using the `geom_smooth()` function by giving `method = "glm"` and `methods.args = list(family = "binomial")` as follows:

```{r, echo = TRUE, eval = TRUE, fig.cap = "Probability of teaching instructor being male by age.", fig.align = "center"} 
ggplot(data = evals.gender, aes(x = age, y = probs.male)) +
  geom_smooth(method="glm", 
              method.args = list(family="binomial"), 
              se = FALSE) +
  labs(x = "Age", y = "Probability of instructor being male")
```

The `plot_model()` function from the `sjPlot` package can also produce the estimated probabilities by `age` as follows:

```{r, echo = TRUE, eval = TRUE, fig.cap = "Probability of teaching instructor being male by age.", fig.align = "center", results = FALSE}
plot_model(model, type = "pred", title = "",
            axis.title = c("Age", "Prob. of instructor being male"))
```

<br>
<br>


